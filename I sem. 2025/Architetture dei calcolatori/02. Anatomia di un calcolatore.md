 > *Lezione del 18/09/2024*

Il cuore di un calcolatore risiede nella sua CPU, e quindi nel suo processore, in italiano.
La parola microprocessore è una parola tecnologica utilizzata per descrivere un processore che poteva essere integrato in un solo chip. Tuttavia, attualmente è un termine abbastanza obsoleto, in quanto qualsiasi processore è chiamato microprocessore per le dimensioni ormai relativamente minime.
## Tipi di processori
- **CPU,** *Central Processing Unit*
- **GPU**, *Graphic Processing Unit* (nasce come coprocessore per i processore)
- **GP-GPU**, *General Purpose GPU*: GPU non utilizzate solo per scopi "grafici" 
- **Microcontrollori**: microprocessori di costo solitamente molto basso, nati per sistemi di tipo industriale
- **DSP**, *Digital Signal Processor*: contenuti all'interno dei cellulari, serve per elaborare segnali digitali. Le GPU nascono come evoluzione dei DSP
- **APU**, *Accelerated Processing Unit*
- **TPU**, *Tensor Processing Unit*: processori fatti da Google per i propri server
- **NPU**, *Neural Processing Unit*: nate esclusivamente per lavorare all'addestramento di reti neurali
Uno dei processori più importanti prodotti da Intel è l'**8086**, nato nel 1976, richiesto da IBM per portare i processori nelle case (attraverso i primi personal computer) e che montava come sistema operativo l'MSDOS da 1Mbyte (anch'esso richiesto da IBM a Microsoft).
I nuovi processori Intel montano anche una NPU, permettendo un utilizzo integrato di CPU, NPU e GPU (ad esempio per lo blurring dello sfondo nelle videochiamate).
I microcontrollori sono microprocessori specializzati per il controllo, soprattutto, di periferiche di I/O, ricevere dati da sensori e controllare attuatori.

---
 > *Lezione del 19/09/2024*

 > **Ada Lovelace:** scrive il primo codice
 
La parola è l'unità di riferimento di un calcolatore. Si dice infatti che una CPU lavora ad n bit se n è la dimensione dei suoi operandi ed n è la dimensione della sua "parola". Attualmente, i calcolatori attuali hanno parola a 32 o 64 bit (4 o 8 byte), ma ne esistono anche con parole di 8, 16 e 128 bit.
La **generazione 0** dei computer era data da calcolatori utilizzati per risolvere calcoli matematici con elementi meccanici ed elettromeccanici.
La **generazione 1** nasce con **ENIAC** (Electronic Numerical Integrator and Computer), progetto americano finanziato dal governo. Era programmabile con interruttori e in modo decimali, composto da circa 18mila tubi a vuoto e 6mila interruttori per programmarlo a mano. **John Von Neumann** lo descrive come *stored program computer*, e pubblica ufficialmente la descrizione del modello di tale calcolatore, rendendolo di dominio pubblico, così da permettere a chiunque di ricrearlo e poterlo migliorare.
![](Images/Pasted%20image%2020240920113405.png)

Attualmente invece l'architettura è fatta in questo modo:
![](Images/Pasted%20image%2020240920113320.png)
- La parte in viola è costituita da chipset, che permettono di scambiare segnali tra CPU e interfacce di memoria, I/O ecc.
## Modelli di architettura
I modelli di architettura odierni sono due:
- architettura di Von Neumann
- architettura di Harvard
![](Images/Pasted%20image%2020240919171016.png)
Quello di Harvard sembra essere quello più efficace, in quanto permette una gestione in parallelo di dati e operazioni, che permette di diminuire i tempi dell'esecuzione grazie ad una sincronizzazione di più eventi (*concetto di pipeline*).

---
 > *Lezione del 23/09/2024*

Per 30 anni, l'architettura di Harvard non venne quasi mai utilizzata, in quanto sostanzialmente più costosa. Questo porta problemi di sicurezza, in quanto il codice e i dati diventano entrambi modificabili se sono contenute in una singola memoria, ma ci permette di avere una forte flessibilità. 
## Prestazioni
Nella progettazione di un calcolatore, bisogna considerare principalmente **efficacia** (l'architettura deve compiere task assegnate in maniera esatta) ed **efficiente** (con un buon compromesso costo/prestazioni o nella maniera più veloce possibile). 
Nella storia dei prodotti commerciali, è ovviamente capitato che sia una o l'altra caratteristica non fossero rispettate, causando problemi anche per quanto riguarda la sicurezza (ad esempio, il primo Intel Pentium venne infatti ritirato dal mercato poco dopo l'uscita).
Alcune CPU lavorano in maniera *speculativa*, ossia "pensando" che alcune operazioni debbano essere eseguire anche se non è detto che servano. Garantire l'efficacia quindi non è sempre facile, ma attualmente i calcolatori messi in vendita garantiscono **efficacia 1**.
Per quanto riguarda le prestazioni, i principali concetti da tenere a mente sono:
- **velocità**, solitamente sintomo di efficienza. E' l'aspetto più importante di un calcolatore
- **risorse e numero di componenti**
- **area**: la dimensione del sistema
- **consumo**: l'ecologia delle nostre macchine è diventato un aspetto importante soprattutto negli ultimi anni (per quanto riguarda la CPU, per esempio, possibilità di chiusura dell'alimentazione di blocchi separati nel momento in cui questi non vengono utilizzati)
- **standardizzazione**: possibilità, ad esempio, di replicare, mantenere e aggiornare nel tempo l'architettura
- **affidabilità**, e quindi tolleranza ai guasti
- **tempi di realizzazione**: il tempo di realizzazione di un sistema deve essere al passo con i tempi di mercato
## Velocità
Per calcolare la velocità, bisogna prendere un task e farlo eseguire al calcolatore nel minor tempo possibile. La massima velocità corrisponde quindi ad un minimo **tempo di esecuzione**. Tuttavia, il calcolatore esegue task ripetitive. La quantità di task eseguite nell'unità di tempo è il cosiddetto ***throughput*** (tendenzialmente è più importante questo, in quanto è di estremo interesse il tempo nella quale ogni singolo task viene eseguito). L'unità misura di tale tempo è il **MIPS** ed è qualcosa da massimizzare.
I due tempi non sono assolutamente uno proporzionalmente inverso rispetto all'altro.

Esiste un legame tra le prestazioni e la frequenza di clock. Generalmente, più il periodo di clock è piccolo, più la frequenza è alta, più il calcolatore lavora in maniera veloce.

### Generazione 2
Dal 1955 nasce la **generazione del transistor**. Nel 1961 infatti si arriva ad eseguire 200mila istruzioni per secondo (PDP-1 della DEC). Viene usato al MIT, dove verrà progettato anche il primo schermo. Viene inventato anche il concetto di architettura da parte di IBM e il primo supercalcolatore.

## Bus
Sono sistemi di collegamento multi punto. Definiamo tre tipi di bus:
- data
- address
- control
Esiste inoltre il **bus controller**, anche detto **chipset**, che permette di far interfacciare in modo corretto CPU, I/O e memoria in tempi diversi (segnali *bus ready*).
Aldilà dell'ultimo, questi hanno le seguenti caratteristiche principali:
- dimensione della parola
- tipo di trasferimento
- temporizzazione (informazione della velocità del bus)
- arbitraggio (chi parla e chi risponde all'interno del bus)
Il **Master** è un'unità del bus che gestisce e controlla il trasferimento delle informazioni sul bus da parte dei **Driver**, unità di trasmissione delle informazioni.
##### Architettura senza bus controller:
- E' un tipo di architettura più lenta, in quanto CPU, I/O e memoria si collegano tramite i bus con gli stessi tempo
![](Images/Architettura%20senza%20bus%20di%20controllo.png)
##### Architettura con chipset:
- Come detto in precedenza, è molto più rapida per la differenziazione dei tempi
![](Images/Architettura%20con%20bus%20di%20controllo.png)

### Generazione 3
E' la generazione dei **circuiti integrati**. Il calcolatore si miniaturizza, diventa più veloce, e permette la nascita della **multi-programmazione**. Nascono i primi **minicomputer**. 

## Architettura a registri
L'architettura nasce con un'architettura ad **accumulatore** (un unico registro per tutte le operazioni), per poi evolversi a **registro ad uso specifico** (i registri sono assegnati a tipi di task specifici), e infine a **registri ortogonali** (qualsiasi registro può compiere task di qualsiasi tipo).
Delle architetture a registro ne esistono di due tipi:
- ***register-register***: architetture più semplici i cui trasferimenti e le operazioni vengono effettuate solamente tra registri. Alcune operazioni specifiche sono invece registro-memoria. L'ALU lavora quindi solo con i registri. Sono più semplici ma necessitano di più istruzioni.
- ***register-memory***: l'ALU può interagire anche con la memoria in questo caso.
Preferire la prima architettura significa poter mantenere un bilanciamento tra le operazioni, permettendo una progettazione più facile e una pipeline più gestibile.
## VAX
Il VAX MIPS, ***Virtual Address extension*** stato uno dei calcolatori più venduti al mondo, e fu il primo computer a poter fare 1mln di istruzioni al secondo.

### Generazione 4
Nasce il concetto di VLSI (*very large integration scale*). Sempre più miniaturizzazione. Nasce la fabbricazione con il **modello a wafer**.
## Personal Computer
Fine anni '70 - '80, vengono venduti i primi **personal computer** con kit di montaggio in casa. L'**IBM** decide di investire sul venditori di terze parti come **Intel**, dopo la pubblicazione dell'ISA. Esplode quindi il mercato dei cloni e nasce grazie ad Intel l'**8086**.
Nel frattempo Steve Jobs costruisce il suo primo **Apple**, e nell'84 viene creata la Apple MacIntosh con la prima **GUI** (*global user interface*).
I processori iniziano a diventare sempre più complicati, e all'inizio degli anni '80 nasce il concetto di **RISC** (*reduced instruction set computer*), in contrasto al **CISC** (*complex instruction set computer*). Lo studio del software permette di scoprire infatti che l'80% del codice usava solo il 20% delle istruzioni presenti nell'ISA, e quindi è possibile creare calcolatori più semplici che eseguono meno operazioni e in maniera più efficiente:
- ISA più semplice
- registri ortogonali, tipicamente *load-store*
- architettura efficace e parallela con impiego di ***pipeline***
La nascita dei RISC permette la nascita in parallelo di altre macchine, che anche non scoppiando sotto il punto di vista del mercato, permisero la creazione successiva dei **motori grafici** (alla base dei sistemi Nintendo, Playstation ecc.).

### Tempi odierni
Le generazioni vengono ormai abbandonate, con l'ultima generazione avuta n.5, nata con il Giappone per l'indicazione di computer basati sull'intelligenza artificiale (ai tempi idea non supportata in quanto il Giappone non aveva lo stesso potere mondiale attuale).
Negli ultimi 20 anni è cambiata soprattutto **l'uniformità dei calcolatori**. Le aziende infatti sono specializzate e ognuno lavora in proprio.

## CPU-bound e I/O-bound
Server o software **CPU-bound** sono software o server limitati dalle prestazioni delle CPU, mentre come suggerisce tale definizione, nel secondo caso significa che sono limitate dai dati in input e in output.
 > **Es.**
 > Un rendering grafico, il calcolo di previsioni metereologiche o l'addestramento di una rete neurale sono esempi di un'applicazione CPU-bound. Un'applicazione di booking invece può essere un esempio di IO-bound (grande utilizzo delle memorie di massa).
 
Tendenzialmente i primi server hanno come caratteristica:
- elevato utilizzo della CPU
- task intensivi di calcolo
- coprocessori grafici
- minore dipendenza da operazioni di I/O
I secondi invece gestiscono principalmente grandi operazioni di scrittura e lettura.

Negli ultimi anni i processori hanno ricominciato a differenziarsi ed ibridizzarsi, grazie anche alla disponibilità di **processori open source** come l'A12 ARM. 