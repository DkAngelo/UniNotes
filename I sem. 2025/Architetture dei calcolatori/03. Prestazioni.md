 > *Lezione del 25/09/2024*

Nella trasformazione tra HLL (*high level language*) e ISA c'è un relativo **gap semantico**, che dipende essenzialmente dalla facilità o meno della trasformazione da un tipo di linguaggio all'altro. Costruire una macchina efficiente significa avere una macchina che permette di passare da un tipo di linguaggio all'altro senza errori e in maniera veloce. Questo gap solitamente veniva ridotto grazie ad istruzioni di grande complessità. Tuttavia, un ISA complesso rende anche l'hardware complesso, e questo crea delle limitazioni (l'hardware stesso non può essere più complesso di un certo livello). E' così che ha quindi inizio la rivoluzione dei RISC.
## DSA - Domain specific architecture
Tra i sistemi generical purpose, alcune case costruttrici hanno ottimizzato i calcolatori in un insieme di cose, nonostante possano continuare a fare comunque qualsiasi operazione. Tali tipi di architettura vengono chiamate **DSA, *domain specific architecture***, architetture basate su una CPU più qualcosa d'appoggio in base all'ambito:
- lavorazione in parallelo: aggiunta di GPU
- off-load di network non particolarmente efficiente: aggiunta di chip SIPho
- computer ultra-complessi: aggiunta di quantum computer
- ecc.
---
 > *Lezione del 23/09/2024*
 
- Tempo di risposta: tempo dall'inizio alla fine di un task, chiamato anche **elapsed time**
- Tempo di esecuzione: tempo esattamente utilizzato dalla CPU per eseguire un determinato task
- Latenza: si usa più per le memoria, ma il concetto del tempo di lavoro dall'inizio alla fine è sempre lo stesso
## Misurazione delle prestazioni
Esistono essenzialmente tre modi per vedere le prestazioni di un processore:
- **simulazione e profilazione:** usare dei software che simulano un architettura, ci permettono di simulare il funzionamento passo passo di una CPU o di un'intero calcolatore. Solitamente si usa per vedere quanto un cambiamento architetturale influisca sulle prestazioni. I profilatori sono un tipo specifico di simulatore di CPU.
- **benchmark:** software progettati per studiare il comportamento di una parte o di tutto il calcolatore in situazioni di stress.
- **modelli analitici:** modelli matematici, di solito semplificati, che ci permettono di capire come sta funzionando il calcolatore. Permette un'analisi a grandi linee.
## Simulatori
Non molto comuni e di solito software proprietari, ne esistono di diversi tipi:
- simulatori di sistema completo
- simulatori di microarchitettura
Dal punto di vista del dettaglio:
- simulatori funzionali (simulatori di set di istruzioni)
- simulatori di temporizzazioni (uguali ai precedenti ma con l'aggiunta di informazioni temporali, di solito in clock)
Poi ancora:
- simulatori basati su traccia (anche detti *basati su eventi*)
- simulatori basati su esecuzione (*profilatori*): identificazione dei colli di bottiglia, utilizzo della cache, analisi dei thread, analisi dell'efficienza energetica ecc.
## Modelli analitici
Si parla di tempo assoluto, anche se il riferimento è sempre al tempo trascorso, e tiene conto di:
- tempi di CPU
- tempi di accesso in memoria
- tempi di I/O
Solitamente il tempo di CPU e il tempo di accesso in memoria vengono considerati in un unico tempo. Il tempo di CPU è inoltre diviso in tempo di utente e il tempo di Sistema Operativo.
##### Formula 1: $$T_{CPU}=N_{CC}\cdot T_{CK}$$
$$T_{CPU}=\frac{N_{CC}}{f_{CK}}_{}$$
Dove: $T_{CPU}$ è il tempo di CPU,  $N_{CC}$ è il numero di giri di clock, $T_{CK}$ il tempo di clock e $f_{CK}$ la frequenza di clock.

##### Formula 2:
$$T_{CPU}=NI\cdot CPI\cdot T_{CK}$$
 > **CPI**, ***clock per instruction*:** numero di periodi di clock (medi) impiegati per eseguire un'istruzione considerando un insieme di programmi su una specifica CPU. I tipi di istruzioni possibili di CPU sono:
 > - **Istruzioni di ALU:** istruzioni coinvolgenti calcoli
 > - **Istruzioni load-store:** per leggere e scrivere da e sulle memorie
 > - **Istruzioni di controllo:** per controllare tutto il sistema (es. istruzione di Reset)

- **CPI medio**
$$CPI=\frac{N_{CC}}{NI}$$
Oppure:
$$CPI=\sum_{i=1}^{n}\left(x_{i}\cdot CPI_{i}\right)$$
- $N_{CC}$ = numero di clock count
- $NI$ = numero di istruzioni diverse
- $x_{i}$ = occorrenza media dell'istruzione i-esima in un programma 
- $CPI_{i}$ = clock per instruction dell'istruzione i-esima

$NI$ dipende dall'ISA e dal grado di ottimizzazione del compilatore, $CPI$ dipende dall'architettura, dal repertorio delle istruzioni e dal calcolatore, mentre $T_{CK}$ o $f_{CK}$ dipendono alla tecnologia e organizzazione architetturale della CPU.

---
 > *Lezione del 25/09/2024*

## MIPS - Mega Instruction Per Second
Il MIPS è un termine di paragone se e solo se **si confrontano architettura con gli stessi ISA**. Il MIPS viene infatti calcolato in questo modo:
$$MIPS=\frac{NI}{CPU_{time}\cdot10^6}$$
Inoltre:$$MIPS=\frac{f_{CK}}{CPI_{medio}}$$
Si nota quanto il MIPS dipende per l'appunto da quanti $CPI$ abbia la nostra macchina. 
Come i MIPS inoltre abbiamo anche i **MFLOPS (*megaflops*)** e **GFLOPS (*gigaflops*)**, ossia mega e giga floating instruction per second.
## Speed-up
Per avere un cosiddetto **speed-up** bisogna vedere quanto la prestazione di un nuovo calcolatore sia migliorata rispetto alla vecchia architettura:
$$SP=\frac{P_{new}}{P_{old}}=\frac{T_{exec-new}}{T_{exec-old}}$$
Tale speed-up dipende dalla frequenza d'uso del miglioramento (se cerco di migliorare qualcosa, cerco di migliorare tutto ciò che uso di più). Tale concetto viene chiamato **legge di Amdahl** e si traduce nella seguente formula:
$$SP_{overall}=\frac{1}{\left(1-f_{enh}\right)+\frac{f_{enh}}{SP_{enh}}}$$
Dove $f_{enh}$ e $SP_{enh}$ sono la frequenza e lo speed-up della sola parte migliorata.
Ovviamente, se le parti migliorate sono più di una, bisognerà fare una sommatoria:
$$SP_{overall}=\frac{1}{\left(1-\sum_{i=1}^{n}f_{ienh}\right)+\sum_{i=1}^{n}\frac{f_{ienh}}{SP_{ienh}}}$$

> [ vedere gli esercizi dalle slide]

## Legge di Moore
La legge di Moore è una legge dell'elettronica che però è stata applicata anche all'architettura dei calcolatori. Questo perché dagli anni '90 in poi, grazie a tecnologie come le pipeline, le prestazioni sono sempre più migliorate. Tuttavia, negli ultimi 5 anni si dice che la legge di Moore sia morta in tale ambito. Intel infatti richiede di fare, in un ciclo di tre-quattro anni, di fare un ciclo di **miniaturizzazione** (miglioramento dei processi) e un ciclo di **miglioramento dell'architettura**, più un ciclo di ottimizzazione, prima del raddoppio dei transistor.
Tale approccio prende il nome di **PAO**, ***Process-Architecture-Optimization***.
## Benchmark
Esistono tendenzialmente tre tipi di benchmark:
- **reali**: sono un insieme di programmi utilizzati per testare le capacità di un calcolatore, decisi da un insieme di produttori chiamata **SPEC** (creano delle ***suite***)
- **ridotti o kernel**: sono fatti da pezzi di applicazioni reali (insiemi di librerie e/o funzioni), nate per stressare solo parti delle CPU
- **microbenchmark**: sequenze di istruzioni che verificano e simulano le parti più frequenti di una CPU
Uno dei più importanti è il ***Linpack***, utilizzato per testare i supercalcolatori, ma anche ***Dhrystone*** e ***Whetstone*** (tutti e tre sintetici puri).
---
 > *Lezione del 03/10/2024*

I primi due sono puramente **applicativi** (sono una sequenza di istruzioni, che non hanno una precisa semantica, ma servono comunque a stressare parti di CPU) e vengono spesso utilizzati dalle case costruttrici, mentre l'ultimo è di tipo **sintetico**.
I benchmark devono essere:
- **rilevanti**: devono misurare caratteristiche di relativa importanza
- **rappresentativi**: devono essere accettati dall'industria e dal mondo accademico
- **equi**: non devono favorire alcune case costruttrici
- **reperibili**: devono essere verificabili
- **economicamente convenienti** 
- **scalabili**: devono funzionare su sistemi con una gamma di risorse scarsa o potente, senza dover riprogettare gli stessi
- **trasparenti:** devono essere di facile comprensione

Nella ***suite*** ***SPEC2006*** erano presenti un compiler C, un gioco di scacchi.

All-interno del **Linpack Benchmark** sono presenti due parametri:
- Rmax - Maximal Linpack performance achieved
- Rpeak - Thorical peak performance
Il Linpack viene utilizzato per creare la top500 dei supercalcolatori. Nel 2013 Cineca ha installato il FERMI nei primi 100 al mondo in tale top.