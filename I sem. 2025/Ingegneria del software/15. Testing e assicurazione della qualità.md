 > *Lezione del 27/11/2024*

Il testing è una fase che richiede di scoprire gli errori in un prodotto software. Bisogna agire attraverso tecniche per l'**assicurazione della qualità** e il **controllo della stessa**. Il problema è che il software ha una **struttura statica** e **dinamica**, e deve essere valutato in entrambe (lo stesso manuale dell'utente o i commenti devono essere valutati). L'analisi statica permette di avere delle tecniche che ci permettono di verificare che il software funzioni.
Il software può essere di qualità perché è **conforme alle specifiche** o perché **svolge la sua funzione**. Sono due cose che potrebbero coincidere come non. La prima attività richiede una fase di **verifica** (dice se il prodotto è stato costruito correttamente e viene eseguita dagli sviluppatori; è una valutazione oggettiva), mentre la seconda una parte di **validazione** (l'utente dovrebbe partecipare per capire se effettivamente il software fa ciò che si aspetta; è una valutazione più soggettiva).
Tutto ciò deve essere eseguito proprio perché ognuno di noi non è esente da errori in quanto umano. Un errore potrebbe portare ad un **difetto** (*bug*), che può portare ad un **fallimento** del software (avviene se il difetto può essere osservato dall'esterno), e quindi dà luogo ad una necessaria correzione. Un errore può essere determinato anche dall'ambiente esterno. Il testing quindi va fatto in condizioni reali, altrimenti tali errori potrebbero non essere notati.
E' impossibile capire quando finire la fase di testing in quando non sappiamo mai se abbiamo corretto tutti gli errori del software. Nonostante tutto, il testing non permette di evitare tutti i difetti del software, ma permette di evitarli nelle casistiche testate. La loro pianificazione diventa quindi relativamente importante.
I difetti possono avere una certa **severità**, ossia un determinato impatto sul funzionamento del nostro prodotto, è una certa **importanza**, ossia quante volte si ripresenta tale difetto. In base a queste due caratteristiche, viene loro assegnata una **priorità** nella correzione
La fase di testing viene definita come un esame **sistematico** (deve essere pianificata) e **metodologico** (è un processo) per mostrare se il software soddisfa gli scopi desiderati o programmati. I test sono fatti dai programmatori, dai tester e dagli utenti stessi.
Incominciare ben presto con i test riduce i costi e il tempo per il risviluppo di alcune parti del software e permette di produrre un software senza errori da poter rilasciare all'utente.
I test possono essere:
- **funzionali**: requisiti funzionali; black box test in quanto dobbiamo vederlo dal punto di vista dell'utente. Si valutano input e output per vedere che le specifiche siano state implementate in maniera corretta, completa e appropriata
- **non funzionali**: requisiti non funzionali; si dividono in 
	- test di **performance**, che misura il tempo che impiega il software in determinati scenari,
	- **stress testing**, test sul comportamento del software in condizioni anormali,
	- test di **usabilità**, per verificare dove il software può essere migliorato,
	- test di **sicurezza**,
	- test di **portabilità**, per verificare quanto il software funzioni su qualsiasi piattaforma
- **white box** (si focalizzano sul codice)
- **regression test** (dopo la correzione del codice)

![](Images/Pasted%20image%2020241127110127.png)
Gli **unit test** sono il più basso livello di testing e vengono effettuati in isolamento dal resto del sistema. Analizzano i requisiti funzionali, non funzionali e strutturali di una parte del codice. 
L'**integration test** va ad unire diverse unità, quindi verifica il comportamento delle parti quando vengono messe in relazione tra di loro.
Il **system test** permette di verificare come le funzioni vengono implementate in uno stesso ambiente, mentre l'**acceptance test** permette di far capire all'utente che il software funziona come richiesto (non si usa per far emergere degli errori, viene solitamente fatto alla fine).

---
 > *Lezione del 4/12/2024*

Per fare i test bisogna avere:
- una base (codice sorgente)
- le condizioni di testing
- il *test case*, ossia lo scenario da verificare
- una procedura
Avendo noi descritto il software potremmo capire cosa verificare tramite **intuizione**, in quanto sappiamo quali parti di codice sono critiche o complesse, ma è possibile utilizzare anche test già fatti. Capire dov'è contenuto un errore potrebbe permettere di capire anche dove sta la maggior parte degli errori, in quanto solitamente non sono equamente distribuiti, ma l'80% degli errori è contenuto nel 20% del codice.
### Principi del testing: 
- scoprono la presenza di errori, non la loro non esistenza; 
- è impossibile verificare tutto;
- iniziare subito permette di risparmiare tempo e soldi; 
- i difetti sono solitamente clusterizzati; 
- fare lo stesso test di continuo non permette di cercare nuovi difetti
#### Processo di testing
![](Images/Pasted%20image%2020241207124454.png)
## Static Testing
Il test statico del software viene chiamata anche **review** ed è il controllo del codice fatto da altri programmatori (e anche altri documenti) per trovare degli errori. Permette di aumentare la qualità e la conoscenza del software stesso.
Le review possono essere **informali**, nel momento in cui ha un processo generico e non ha un output documentato, oppure **formali**. 
Una review formale solitamente avviene tramite una check list, nella quale sono contenute le caratteristiche da verificare all'interno del codice e non, e con un processo definito:
![](Images/Pasted%20image%2020241207125607.png)
A seconda del livello di formalità a cui ci troviamo avremo bisogno di documenti e figure diverse.
![](Images/Pasted%20image%2020241207130108.png)
La review quindi può avvenire tramite:
- tecniche ad-hoc
- checklist
- scenari e dry runs (esecuzioni del software su carta)
- role based (si cerca di impersonificare un ruolo di utilizzo del software, ad esempio utente standard, utente registrato, admin ecc.)
- basata sulla prospettiva
Gli operatori di successo di una review sono i fattori organizzativi e legati alle persone.
## Black-Box testing
Controlliamo il software come se fossimo un utente, testandolo quindi ad alto livello. I vantaggi sono la non occorrenza di conoscere il software e il fatto che si viene a tesare la prospettiva più importante. Come svantaggio abbiamo però la non conoscenza delle condizioni da verificare (l'utente verifica quello che lui vuole verificare) e quanto codice sia stato effettivamente verificato.
Le tecniche di black-box testing sono:
- **equivalent partitioning**: l'input dell'applicazione deve essere diviso in classi equivalenti sotto il punto di vista del funzionamento (vanno testate sia classi valide che invalide). Tuttavia è inutile provare tutte classi invalide, in quanto non ci permettono di capire dove sta l'errore. Si preferisce quindi che ci sia una combinazione di classi nella quale solo una sia invalida. 
  Il test minimo ci permette di pensare ogni classe come indipendente dalle altre e che ogni classe valida dovrà essere verificata almeno una volta.
  I test validi sono formati da classi solo valide, i test invalidi hanno al loro interno una sola classe invalida.
- **boundary value analysis**: se dobbiamo verificare dei valori all'interno del codice, bisogna utilizzare un valore minimo, un valore massimo, un valore nominale (quello che si pensa essere il più diffuso in media) ed eventualmente il valore successivo e precedente ai valori estremi.
- **decision table testing**
- **use case testing**
Normalmente ci si concentra sulle prime due.
---
Per fare i test bisogna avere:
- una base (codice sorgente) 
- le condizioni di testing
- il _test case_, ossia lo scenario da verificare
- una procedura
Avendo noi descritto il software potremmo capire cosa verificare tramite **intuizione**, in quanto sappiamo quali parti di codice sono critiche o complesse, ma è possibile utilizzare anche test già fatti. Capire dov'è contenuto un errore potrebbe permettere di capire anche dove sta la maggior parte degli errori, in quanto solitamente non sono equamente distribuiti, ma l'80% degli errori è contenuto nel 20% del codice.
## Principi del testing
- scoprono la presenza di errori, non la loro non esistenza;
- è impossibile verificare tutto;
- iniziare subito permette di risparmiare tempo e soldi;
- i difetti sono solitamente clusterizzati;
- fare lo stesso test di continuo non permette di cercare nuovi difetti.
### Processo di testing
![](Images/Pasted%20image%2020241226162923.png)
## Static testing
Il test statico del software viene chiamata anche **review** ed è il controllo del codice fatto da altri programmatori (e anche altri documenti) per trovare degli errori. Permette di aumentare la qualità e la conoscenza del software stesso.
Le review possono essere **informali**, nel momento in cui ha un processo generico e non ha un output documentato, oppure **formali**.
Una review formale solitamente avviene tramite una check list, nella quale sono contenute le caratteristiche da verificare all'interno del codice e non, e con un processo definito:
![](Images/Pasted%20image%2020241226163038.png)
A seconda del livello di formalità a cui ci troviamo avremo bisogno di documenti e figure diverse.
![](Images/Pasted%20image%2020241226163105.png)
La review quindi può avvenire tramite:
- tecniche ad-hoc
- checklist
- scenari e dry-runs (esecuzioni del software su carta)
- role based (si cerca di impersonificare un ruolo di utilizzo del software, ad esempio utente standard, utente registrato, admin ecc.)
- basata sulla prospettiva
Gli operatori di successo di una review sono i fattori organizzativi e legati alle persone.
## Black-box testing
Controlliamo il software come se fossimo un utente, testandolo quindi ad alto livello. I vantaggi sono la non occorrenza di conoscere il software e il fatto che si viene a tesare la prospettiva più importante. Come svantaggio abbiamo però la non conoscenza delle condizioni da verificare (l'utente verifica quello che lui vuole verificare) e quanto codice sia stato effettivamente verificato.
Le tecniche di black-box testing sono:
- **equivalent partitioning**: l'input dell'applicazione deve essere diviso in classi equivalenti sotto il punto di vista del funzionamento (vanno testate sia classi valide che invalide).
  Tuttavia è inutile provare tutte classi invalide, in quanto non ci permettono di capire dove sta l'errore. Si preferisce quindi che ci sia una combinazione di classi nella quale solo una sia invalida.
  Il test minimo ci permette di pensare ogni classe come indipendente dalle altre e che ogni classe valida dovrà essere verificata almeno una volta.
  I test validi sono formati da classi solo valide, i test invalidi hanno al loro interno una sola classe invalida.
- **boundary value analysis**: se dobbiamo verificare dei valori all'interno del codice, bisogna utilizzare un valore minimo, un valore massimo, un valore nominale (quello che si pensa essere il più diffuso in media) ed eventualmente il valore successivo e precedente ai valori estremi.
- decision table testing
- use case testing
Normalmente ci si concentra sulle prime due.
#### Decision table testing
Vediamo le combinazioni delle classi  di equivalenza e mi danno delle decisioni. Così andiamo a valutare il comportamento atteso dalle classi di equivalenza e come questo comportamento agisce sul risultato atteso della applicazione
#### Use case testing
Viene usato lo use case come sorgente dei test. Se si utilizza una forma taellare, bisognerà quindi testarne ogni riga.
#### White box testing
Il test black box può coprire una parte non specifica del codice. Per coprirlo interamente viene usato il white box testing, pensato come blocchi di istruzioni che vengono eseguite, decisioni e giunzioni.
**es.**
![](Images/Pasted%20image%2020241226163609.png)
#### Statement coverage: 
Dobbiamo fare dei test che coprano tutte le linee di codice. E’ possibile quindi misurare la qualità di un white box testing in base al codice che andiamo a coprire (nel caso di esempio, 8 blocchi su 12 righe di codice). **Beizer**, tuttavia, dice che **tutte le linee di codice devono essere testate almeno una volta**, in quanto altrimenti non sappiamo come si comporta il nostro software in quelle linee di codice. Bisogna non farci confonder dalla nostra percezione del codice, in quanto dove pensiamo che potrebbe non esserci un errore in realtà può esserci eccome. 
#### Decision coverage:
Coprire tutte le linee di codice una volta soltanto, nonostante la copertura del software sia il 100%, non ci esenta dalla presenza di errori non testati.  
A questo punto piuttosto che testare le linee di codice stesse, bisognerebbe testare le decisioni. Questo tipo di test si chiama **decision coverage,** che implica anche lo **statement coverage**. Provare tutte le decisioni permette di verificare quindi anche tutto il codice.
Questi due tipi di codice sono il minimo da dover fare


---
- non tanto memorizzare le n versioni, quanto più i legami tra esse e tra i requisiti di queste
- gestire gli artefatti, come i documenti, le classi, il codice e così via, e le loro relazioni
Per mantenere informazioni simili il sistema è complesso ma è utilissimo: l'**inter-artifacts relationship matrix**.
[ aggiungi immagine ]
La complessità aumenta con il crescere delle versioni prodotte (produzioni diverse per ogni linguaggio, oppure versioni speciali per consumatori specifici). Bisognerà quindi tener traccia delle varie versioni e customizzazioni del prodotto.
Quello su cui si basano tutti questi sistemi è un **naming parlante** in cui per ogni parte del prodotto vi è un codice che li identifica. Tali sistemi hanno elementi per creare, vedere, eliminare repository, modificare e tirare fuori elementi contenuti al loro interno, mettere insieme file eventualmente conflittuali, gestire i conflitti tramite segnalazioni ecc.