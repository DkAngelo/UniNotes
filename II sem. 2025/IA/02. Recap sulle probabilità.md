 >*Lezione del 04/03/2024*

Ogni elemento nella realtà ha una componente stocastica, e questo ci impone di utilizzare le probabilità, soprattutto per quanto riguarda la stima di eventi futuri (data l'incertezza che il nostro risultato sia effettivamente quello corretto).
La maggior parte delle teorie legate al machine learning per quanto riguarda le probabilità sono dovute a **Thomas Bayes**, il quale introduce l'inferenza tramite *la regola di Bayes*.
#### Inferenza
Date le informazioni di un fenomeno osservato, qual è l'implicazione su una variabile non osservata.
Prima di Bayes l'approccio alle probabilità era di approccio *frequentista*, ossia semplicemente valutando un certo evento "contando", senza previsioni sul futuro. Nell'approccio baiesiano cerchiamo di "indovinare" qual è il risultato di qualcosa che non abbiamo osservato in base a quello che abbiamo già osservato
#### Spazio dei campioni:
E' lo spazio dato da tutti i possibili risultati di un esperimento
#### Probabilità
E' una funzione di mapping $P:A\subseteq S\to\left\lbrack0,1\right\rbrack$ (*A* è un sottoinsieme dello spazio di campionamento *S*) che ha le seguente proprietà:
- è sempre non negativa: $( P(A) \geq 0 )$ per ogni  $A \subseteq S$ **(non negatività)**
- la somma della funzione su tutti i campioni vale 1: $P\left(S\right)=1$ **(normalizzazione)**
- $P\left(\bigcup_{i}A_{i}\right)=\sum_{i}P\left(A_{i}\right)$ se $A_{i}\cap A_{j}=\emptyset$ **(additività)** 
Da queste proprietà si ricavano le seguenti proprietà secondarie:
- $0 \leq P(A) \leq 1$
- $P(\emptyset)=0$
- $A \subseteq B \Rightarrow P(A) \leq P(B)$
- $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
- $P(S \setminus A) = 1 - P(A)$
#### Variabili aleatorie
Una variabile aleatoria è definita come una funzione che associa un valore ad ogni evento dello spazio di campionamento. E' definita attraverso le seguenti proprietà:
- Per ogni variabile aleatoria $X$ con dominio discreto $\Omega$ :
	1. $P\left(X=x\right)\in\R$ denota che $X=x$ per qualche $x\in\Omega$
	2. 
Omega può essere o uno scalare o un insieme di valori.
Qualsiasi evento considerato potrebbe essere definito come una variabile aleatoria, e quindi può essere considerato come evento probabilistico.
#### Altre definizioni
- Distribuzione congiunta: probabilità che due eventi accadano contemporaneamente. Prevede che le due variabili aleatorie accadano insieme
Sulla distribuzione congiunta posso andare ad applicare le seguenti proprietà:
- marginalità [Aggiungi formula]
- probabilità condizionata [Aggiungi formula] (se accade Y, evento osservato, qual è la probabilità che accada X, evento stimato)
- se due variabili aleatorie sono totalmente indipendenti, la loro probabilità congiunta è il prodotto tra le probabilità, mentre la probabilità condizionata dell'uno o dell'altro è pari alla probabilità solo dell'uno o dell'altro [Aggiungi formula]
Tramite le formule viste in precedenza, possiamo ottenere le seguenti altre formule:
- regola del prodotto
- teorema di Bayes
Se hai più variabili aleatorie, sarà possibile riscrivere le formule già viste in questo modo:

Non cambia nulla sotto il punto di vista teorico, ma sarà ovviamente più difficile in quanto la nostra variabile aleatoria non è più unica ma è un vettore.
## Densità di probabilità
E' una funzione che mappa da una variabile aleatoria ad uno scalare che ha codominio in $\left\lbrack0,\infty\right\rbrack$.
[Formula]
La distribuzione di probabilità cumulativa è la seguente:
[Formula]
Ovviamente nel discreto si passa ad una semplice somma.
Si passa quindi da una densità alla probabilità semplicemente integrando.
#### Densità di probabilità note:
1. **Gaussiana in una dimensione** 
	[ Formula e immagine grafico ]
	Sotto il punto di vista grafico, è una campana centrata sulla media e di ampiezza pari alla deviazione standard.
2. **Gaussiana multidimensionale**
	[ Formule ]
	La media diventa una media sul vettore:
	Sigma diventa una **matrice di covarianza**:
	Sulla diagonale di questa matrice viene fornita la **varianza** di ogni singola variabile, mentre nelle altre posizione le variazioni mutuali. Tale matrice è simmetrica e **semidefinita positiva** (determinante maggiore o uguale a 0). La formula $\left(x-\mu\right)^{T}\sum_{}^{} \left(x-\mu\right)$ (la sommatoria è alla meno 1), sotto il punto di vista geometrica, identifica un ellisse, base della nostra gaussiana, che sarà quindi un ellissoide.
3. **Bernoulliana**
	La nostra variabile aleatoria è **binaria**, quindi può assumere valori solo 0 e 1. La bernoulliana ci permette di sapere la probabilità che la nostra variabile abbia valore 1. E' parametrizzata da uno scalare $\mu$.
	[ Formule]
	La probabilità che tutte le variabili di un dataset assumano una configurazione assegnata viene calcolata come:
	[ Formula ]
	Se il nostro obiettivo è invece calcolare il $\mu$ ottimo, allora scriviamo:
	[ Formula ]
	(***Maximum likelihood***)
4. **Binomiale**
	Deriva dal teorema delle prove ripetute, il quale stima qual è la probabilità di una variabile binaria se ripeto l'osservazione di tale variabile *n* volte. Quindi *n* sarà il numero di esperimenti, *m* sarà il numero di successi, $\mu$ sarà la probabilità che l'evento ennesimo sia effettivamente un successo:
	[ Formula ]
5. **Multinomiale**
	La nostra variabile non è più binaria, ma può assumere n valori. Ogni valore possibile si porta dietro il suo $\mu$. 
	La probabilità che il dataset abbia una determinata configurazione assegnata è la seguente:
	dove $m_{k}$ è il numero di volte in cui $x_{i}=k$
	Per massimizzare $\mu$ quindi:
## Metodo di Monte Carlo
Abbiamo detto che per passare da distribuzioni a probabilità bisogna integrale, ma non sempre è possibile. Quello che si fa spesso quindi è quello di approssimare l'integrale ad una somma, fatta su degli elementi. Idealmente, se questo numero di elementi tendesse ad infinito l'integrale e tale somma convergerebbero, ma essendo questo impossibile nella realtà, verrà sicuramente pagato un certo prezzo.
Uno degli esempi di applicazione è il calcolo della media di una funzione di distribuzione:
[ Formula ]
Questa cosa viene chiamata **metodo Monte Carlo**, il quale ci permette di calcolare tali integrali in modo empirico (genera variabili aleatorie casuali sul quale approssimare gli integrali).
#### Rejection sampling [vedi da slide e aggiungi info]
Rigetto alcuni valori:
- campiono una x nel sample
- calcolo la probabilità di tale x . Aggiungo una soglia, se tale rapporto è superiore a tale soglia allora tengo in conto x, altrimenti no
- ripeto fino a che abbiamo un numero di x prese da parte soddisfacente
#### Importance sampling
Non butta via nessun campione, ma attribuisce ad ogni campione un peso. Tale peso non è altro che funzionale al rapporto tra $p\left(x\right)$ e $q\left(x\right)$. E' importante però scegliere bene $q\left(x\right)$, tale da farla avvicinare alla $p\left(x\right)$. Col tendere di tale sommatoria all'inifinito, l'integrale e la somma convergono, per cui al limite bisognerà aumentare il numero di sample presi in considerazione.